{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2srjHZF-G7q7"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnXVA1XAGr-6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2srjHZF-G7q7"
      },
      "source": [
        "# Data Import, Visualization, and Troubleshooting with Python\n",
        "\n",
        "**Expected study time :** 45 min (depending on your background)\n",
        "\n",
        "**Learning outcomes :**\n",
        "\n",
        "*Adapt an existing Python script in google colab in order to:*\n",
        "- Load data from your geosensor\n",
        "- Import data into Python\n",
        "- Visualize the data\n",
        "- Refine and export figures for presentation\n",
        "- Perform basic statistics to support a scientific finding\n",
        "\n",
        "**External References**\n",
        "- the Scipy.stat module https://docs.scipy.org/doc/scipy/reference/stats.html\n",
        "- Matplotlib cheat sheet https://github.com/matplotlib/cheatsheets\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i74aQwVJUX0"
      },
      "source": [
        "# 1.   Load Packages\n",
        "\n",
        "First step is to import Python libraries to analyse and visualise data. We will use\n",
        "\n",
        "*   NumPy - mathematical functions, random number generators, linear algebra routines, Fourier transforms, and more\n",
        "*   MatPlotLib - comprehensive library for creating static, animated, and interactive visualizations in Python\n",
        "*   Pandas - fast, powerful, flexible and easy to use open source data analysis and manipulation tool\n",
        "*   Scipy - algorithms for optimization, integration, interpolation, eigenvalue problems, algebraic equations, differential equations, statistics and many other classes of problems\n",
        "*   Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgzZ8IVHJG8s"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0TPuMO-Jb2E"
      },
      "source": [
        "# 2.   Load Data\n",
        "\n",
        "\n",
        "Make sure that your data makes sense.\n",
        "Check that the dates imported correctly.\n",
        "Look at the header and variable names.\n",
        "\n",
        "If you import from github, make sure that you are using the \"raw\" prefix after the https://   ...\n",
        "On google Colab, you also can upload local files.  To do that, click on the \"file\" icon on the left side and then the file with an arrow on it.\n",
        "\n",
        "Look at the header to make sure you data lines up correctly.   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agXw597RJbiA"
      },
      "source": [
        "temp = pd.read_csv('https://raw.githubusercontent.com/nattycep/FIL_Geosensing/main/temp.csv')\n",
        "temp.head()\n",
        "\n",
        "# in this data file -> each component of date was its own column, so it imported as an interger.  We need to convert it to date."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your data is now a \"data frame\".  But to make it easier to work with, let's:   \n",
        "1. Make a single data vector for each variable by extracting columns from the table"
      ],
      "metadata": {
        "id": "nQU32pPiArM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = temp['temperature'].astype(int)\n",
        "#temperature = temperature.astype(int)\n",
        "print(temperature)"
      ],
      "metadata": {
        "id": "oLcwf0SABFci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Delete the successfully extracted colums\n"
      ],
      "metadata": {
        "id": "zNeFLrPPCMBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del temp[\"temperature\"]\n",
        "print(temp)"
      ],
      "metadata": {
        "id": "h__gyqKYCaQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Parsing the remaining columns (date and time) into a datetime vector.  This method expects columns to have headings of minimally \"year\", \"month\", day\""
      ],
      "metadata": {
        "id": "rGYSb4EcCrnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datetime = pd.to_datetime(temp) #converting to a date time is key\n",
        "print(datetime.min()) # allows you to use special functions\n",
        "print(datetime.max())\n",
        "print(np.timedelta64(datetime.max()-datetime.min(),'m')) # declare the untis"
      ],
      "metadata": {
        "id": "lU_8Q-kgST9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can transform this data into a time series and two value series."
      ],
      "metadata": {
        "id": "sQQ601XwMZyk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an easy one -> But I still had to troubleshoot the header:"
      ],
      "metadata": {
        "id": "qmATpbvkGgcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temps = pd.read_csv('https://raw.githubusercontent.com/nattycep/FIL_Geosensing/main/Datalog_geosensorik.csv')\n",
        "print(temps.head())\n",
        "temps_dt = temps.loc[:, [\"Year\",\t\"Month\",\t\"Day\",\t\"Hour\",\t\"Minute\",\t\"Seconds\"]]\n",
        "T_datetime = pd.to_datetime(temps_dt)\n",
        "T_ambient =temps[\"Ambient_Temperature\"]\n",
        "T_object =temps[\"Object_Temperature\"]\n",
        "\n",
        "del(temps)\n",
        "del(temps_dt)"
      ],
      "metadata": {
        "id": "x-YrHvcKK-oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's test your test data\n",
        "\n",
        "1.  I manually uploaded the files, then right clicked to copy path\n"
      ],
      "metadata": {
        "id": "gu0PMidiSzQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Klima1 = pd.read_csv('/content/Datalog_1 2-1.csv')\n",
        "print(Klima1.head())\n",
        "\n",
        "Klima2 = pd.read_csv('/content/Datalog_1 2.csv')\n",
        "print(Klima2.head())\n",
        "\n",
        "Klima3 = pd.read_csv('/content/Datalog_1.csv')\n",
        "print(Klima3.head())\n",
        "\n",
        "Bridge = pd.read_csv('/content/Results_OverNightTest.csv')\n",
        "#On first try, I got this error: 'utf-8' codec can't decode byte 0xb0 in position 19: invalid start byte\n",
        "# if I look, there is a funny character: Date,CO2(ppm),Temp(∞C),CarCount\n",
        "# I cheated and just changed it.\n",
        "print(Bridge.head())\n",
        "\n",
        "Water = pd.read_csv('/content/water.csv', delimiter=\";\") # on my first try, I didn't notice the deliminator was not \",\"\n",
        "print(Water.head())\n"
      ],
      "metadata": {
        "id": "9G5pvDAbTDhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Water:\n",
        "1. Make the date into a date time\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zBvnN4TxU5rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Water.columns= Water.columns.str.lower()\n",
        "print(Water.columns) # the spaces at the beginning of the header names are causeing problems. Later the periods might also\n",
        "headers = Water.columns.str.replace(' ','')\n",
        "Water.columns = headers\n",
        "headers = Water.columns.str.replace('.','')\n",
        "Water.columns = headers\n",
        "print(Water.columns)\n",
        "\n",
        "Water['datetime']=pd.to_datetime(Water.iloc[:,[0,1,2,3,4,5]])\n",
        "\n",
        "print(Water.head())\n",
        "print(Water.dtypes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CCJB34SlVlcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All:\n",
        "1. Check that the date is correct\n",
        "- see that bridge starts 1/1/2021\n"
      ],
      "metadata": {
        "id": "b3tR4dL8j6vA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Bridge.dtypes)\n",
        "Bridge['datetime']=pd.to_datetime(Bridge.Date)\n",
        "print(Bridge.head())"
      ],
      "metadata": {
        "id": "aiTOe2gWjy19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- no date for Klima data\n",
        "\n",
        "\n",
        "Klima:\n",
        "\n",
        "1.   Merge the 3 data sources according to time\n"
      ],
      "metadata": {
        "id": "nDiB9TcAj9Jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(Klima1.dtypes)\n",
        "Klima1['datetime']=pd.to_datetime(Klima1.Time) # assumed that it was today\n",
        "#print(Klima1.dtypes)\n",
        "#print(Klima1.head())\n",
        "Klima2['datetime']=pd.to_datetime(Klima2.Time) # assumed that it was today\n",
        "Klima3['datetime']=pd.to_datetime(Klima3.Time) # assumed that it was today\n",
        "\n",
        "# to merge,first need unique column names\n",
        "\n",
        "#print(Klima1.columns)\n",
        "#print(Klima2.columns)\n",
        "#print(Klima3.columns)\n",
        "\n",
        "\n",
        "Klima1.rename(columns={'Time1':'Time'}, inplace=True)\n",
        "Klima1.rename(columns={'Temp1':'Temperature in C'}, inplace=True)\n",
        "Klima1.rename(columns={'Humid1':'Humidity in %'}, inplace=True)\n",
        "Klima1.rename(columns={'Light1':'Light'}, inplace=True)\n",
        "Klima1.rename(columns={'datetime1':'datetime'}, inplace=True)\n",
        "\n",
        "\n",
        "Klima2.rename(columns={'Time2':'Time'}, inplace=True)\n",
        "Klima2.rename(columns={'Temp2':'Temperature in C'}, inplace=True)\n",
        "Klima2.rename(columns={'Humid2':'Humidity in %'}, inplace=True)\n",
        "Klima2.rename(columns={'Light2':'Light'}, inplace=True)\n",
        "Klima2.rename(columns={'datetime2':'datetime'}, inplace=True)\n",
        "\n",
        "Klima3.rename(columns={'Time3':'Time'}, inplace=True)\n",
        "Klima3.rename(columns={'Temp3':'Temperature in C'}, inplace=True)\n",
        "Klima3.rename(columns={'Humid3':'Humidity in %'}, inplace=True)\n",
        "Klima3.rename(columns={'Light3':'Light'}, inplace=True)\n",
        "Klima3.rename(columns={'datetime3':'datetime'}, inplace=True)\n",
        "\n",
        "Klima12 = pd.merge(Klima1,Klima2, on='datetime', how='outer').sort_values(by='datetime').fillna(method='ffill')\n",
        "Klima = pd.merge(Klima12,Klima3, on='datetime', how='outer').sort_values(by='datetime').fillna(method='ffill')\n",
        "\n",
        "print(Klima.head())\n",
        "\n",
        "del Klima1\n",
        "del Klima2\n",
        "del Klima3\n",
        "del Klima12"
      ],
      "metadata": {
        "id": "CFe0-L8oj_BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "For our example plots, let's work with some meteo suisse data from this weekend.  \n",
        "\n",
        "*   ten-minute resolution\n",
        "*   two stations:\n",
        "    *     NABBER    Bern / Bollwerk\n",
        "    *     BER       Bern / Zollikofen\n",
        "*   two variables\n",
        "    *     tre200s0,  ∞C Air temperature 2 m above ground; current value\n",
        "    *     rre150z0, mm  Precipitation; ten minutes total\n",
        "\n"
      ],
      "metadata": {
        "id": "942q2CKgVlAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"https://raw.githubusercontent.com/nattycep/FIL_Geosensing/main/order_105725_data.txt\"\n",
        "ms = pd.read_csv(path, delimiter= \";\")\n",
        "ms.time= pd.to_datetime(ms['time'].astype(str),errors='raise',format='%Y%m%d%H%M')\n",
        "ms.stn = ms['stn'].astype('category')\n",
        "print(ms.head())\n",
        "print(ms.dtypes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xi1ZqyTaamN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe we want to pivot this, to make a single row for each time\n"
      ],
      "metadata": {
        "id": "Yy326tyII7HH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature = ms.pivot(index='time', columns='stn', values='tre200s0')\n",
        "rain = ms.pivot(index='time', columns='stn', values='rre150z0')\n",
        "\n",
        "print(temperature.head())\n",
        "print(rain.head())\n"
      ],
      "metadata": {
        "id": "3lB7sLuBJAku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.   Make Figures: Preliminary, Refine, Export\n",
        "\n",
        "Start with looking at each variable independently.  For example, a histogram of one variable and a line of another.\n",
        "\n",
        "Remember to always label your axes.\n",
        "\n"
      ],
      "metadata": {
        "id": "_HmhpySYFE9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(temperature.BER)\n",
        "plt.ylabel(\"$ Temperature [^OC]$\")\n",
        "plt.xlabel(\"datetime\")"
      ],
      "metadata": {
        "id": "Z7rI-LwuFMrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram is the most useful plot for seeing the first distribution of the data. Here are two different ways to visualize the histogram, for our two different time series.\n",
        "\n",
        "Note: to get superscript in matplotlib axes labels, use dollar signs that signal equation mode around a carrot (^). Subscripts would be around an underscore (_), and greek similarly need dollar signs but then a back slash followed by the name of the letter (capitalized for the capital version).  i.e.:\n",
        "```\n",
        "plt.ylabel(\"$ \\Delta _{temperature} [^OC]$\")\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y2SfmZ0YFjPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(temperature.BER)\n",
        "plt.xlabel(\"frequency\")\n",
        "plt.ylabel(\" temperature [$^OC$]\")"
      ],
      "metadata": {
        "id": "PmAQ95OuFi2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or basically the same, just called a little differently:"
      ],
      "metadata": {
        "id": "4XVQWf2sLiEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.hist(temperature.BER)\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.xlabel(\"$temperature ^OC$\")\n"
      ],
      "metadata": {
        "id": "4PIvXfNKFinL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or if there are two variables, we can see how their distributions compare."
      ],
      "metadata": {
        "id": "v8bhDP1bDemF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.hist(temperature.BER)\n",
        "ax.hist(temperature.NABBER)\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.xlabel(\"$temperature ^OC$\")\n",
        "ax.legend(labels = {'Zollikofen', 'Bollwerk'})\n",
        "\n",
        "#NABBER Bern / Bollwerk\n",
        "#BER Bern / Zollikofen\n",
        "\n",
        "#plt.hist(norm.rvs(0,1,5000))  # depending on your bins, you see differnet structure. how to decide on binning?\n",
        "# doesn't make sense to have bins that are smaller than the accuracy of your data, i.e. 1 cm.\n",
        "# let python decide\n",
        "# plot with correct uncertainty bars (the best)\n",
        "#plt.hist(norm.rvs(0,1,5000), bins=15)  # depending on your bins, you see differnet structure. how to decide on binning?"
      ],
      "metadata": {
        "id": "d5HR6mqtDlIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe we want to make them transparent"
      ],
      "metadata": {
        "id": "Ls4ZhSEsdWMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "n, bins, patches = ax.hist(temperature.BER, alpha=.5, edgecolor='white') # so that we can match the bins\n",
        "print(bins)\n",
        "ax.hist(temperature.NABBER, alpha=.5, bins = bins, edgecolor='white') # here we use the same bins\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.xlabel(\"$temperature ^OC$\")\n",
        "ax.legend(labels = {'Zollikofen', 'Bollwerk'})\n",
        "\n",
        "print(temperature.BER.mean())\n",
        "print(temperature.NABBER.mean())\n"
      ],
      "metadata": {
        "id": "rSWBAELfGIwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1 Time Series"
      ],
      "metadata": {
        "id": "q4uON3btHYgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(temperature.BER)\n",
        "ax.plot(temperature.NABBER)\n",
        "ax.legend(labels = {'Zollikofen', 'Bollwerk'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mjJpLAu7HXih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the marker"
      ],
      "metadata": {
        "id": "nvEVxeX5HkcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(temperature.BER, 'o')\n",
        "fig.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ACEPEYvCHm0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhaps we want to add a bined function to this figure and make the original data transparent. For this, use grouupby. Another option would be to use scipy binned statistic"
      ],
      "metadata": {
        "id": "DjFOX2yVDXuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note in this concatted data, the index is the time, but in your data it might be a different column, or another variable.\n",
        "\n",
        "temperature.index.min()\n",
        "temperature.index.max()\n",
        "\n",
        "temp6=temperature.groupby(temperature.index.floor('6H')).mean() #anotheroption would 30min or 1D (day)\n",
        "temp6s=temperature.groupby(temperature.index.floor('6H')).std()"
      ],
      "metadata": {
        "id": "tPg-yJ28OFRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's plot these resampled values and add an error bar."
      ],
      "metadata": {
        "id": "7k1sSNU0ZS11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(temperature.BER, 'ro', alpha=0.1)\n",
        "ax.plot(temp6.BER, 'bo-');\n",
        "ax.errorbar(x=temp6.index, y=temp6.BER, yerr=temp6s.BER/2, color='b', capsize=3);  # add error bars\n",
        "\n",
        "fig.show()\n",
        "\n",
        "\n",
        "# note at the 6 hour time step, this isn't so nice.  We really should shift the dates by 3 hours so that the mean points are in the middle."
      ],
      "metadata": {
        "id": "mL2k32AnKXVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perhaps instead of a moving average, we want to fit a function to the data.\n",
        "\n",
        "First a linear function.\n",
        "\n",
        "Let's start by changing our x-variable to a deltatime"
      ],
      "metadata": {
        "id": "weh-8JYwf9Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = temperature.index -temperature.index.min()\n",
        "dtemp = temperature\n",
        "dtemp.index = dt\n",
        "print(dtemp.head())"
      ],
      "metadata": {
        "id": "U-BvOh7VaG0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#linear fit\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.ylabel(\"$Bollwerk_{temperature} [^OC]$\")\n",
        "plt.xlabel(\"$Zollikofen_{temperature} [^OC]$\")\n",
        "p= sns.regplot(data=dtemp, x=dtemp.NABBER.values, y=dtemp.BER.values);\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "XzYWssQHuZgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that regplot makes a it a bit tricky to get the equations, but you can figure them out"
      ],
      "metadata": {
        "id": "T0X6_EQeeUZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "slope, intercept, r_value, p_value, std_err = stats.linregress(x=p.get_lines()[0].get_xdata(),y=p.get_lines()[0].get_ydata())\n",
        "\n",
        "print(slope)\n",
        "print(intercept)\n",
        "print(r_value)\n",
        "print(p_value)\n",
        "print(std_err)\n"
      ],
      "metadata": {
        "id": "fLejfRVxeiAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could make this more interesting by seeing if the relationship varies according to a categorical variable, say if it is raining in either place."
      ],
      "metadata": {
        "id": "DtJ0DFnWdoYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "israining = (rain.BER+rain.NABBER)>0\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "plt.ylabel(\"$Bollwerk_{temperature} [^OC]$\")\n",
        "plt.xlabel(\"$Zollikofen_{temperature} [^OC]$\")\n",
        "p= sns.scatterplot(data=dtemp, x=dtemp.NABBER.values, y=dtemp.BER.values, hue =israining);\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bIRJU3DZd1Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplots\n"
      ],
      "metadata": {
        "id": "uBKYiKlUWuhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot([dtemp.BER, dtemp.NABBER])\n",
        "plt.ylabel(\"temperature ^OC\")\n",
        "locs, labels = plt.xticks()  # Get the current locations and labels.\n",
        "print(locs)\n",
        "plt.xticks(locs, ['Zolli', 'Bollw'],rotation=45)  # Set text labels and properties.\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "47wc06X1ukQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save your figure"
      ],
      "metadata": {
        "id": "5iCwU8rpjClG"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h20muCtpH1b5"
      },
      "source": [
        "fig.savefig(\"mydatavis.png\", dpi=300)\n",
        "\n",
        "fig.savefig(\"mydavavis.pdf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A8he82uJo4d"
      },
      "source": [
        "\n",
        "# 4.  Perform Statistical Tests\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de2rVKG7JrXX"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Save your data"
      ],
      "metadata": {
        "id": "AObYRB1xZPv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temperature.to_csv('export_test.csv', index=False, sep=';')"
      ],
      "metadata": {
        "id": "y1xP5gcyZTAn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}